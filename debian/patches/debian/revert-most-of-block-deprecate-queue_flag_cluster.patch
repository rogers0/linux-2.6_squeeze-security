From: Ben Hutchings <ben@decadent.org.uk>
Subject: [PATCH] Revert most of "block: Deprecate QUEUE_FLAG_CLUSTER ..."

This reverts the API- and ABI-breaking changes in commit
e692cb668fdd5a712c6ed2a2d6f2a36ee83997b4 upstream, included in
stable update 2.6.32.28.

Restore both blk_queue_limits::no_cluster and QUEUE_FLAG_CLUSTER.
Modify blk_queue_cluster() to check both of them, to cope with any
drivers that fail to update them both.

Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

--- a/block/blk-settings.c
+++ b/block/blk-settings.c
@@ -103,7 +103,7 @@
 	lim->alignment_offset = 0;
 	lim->io_opt = 0;
 	lim->misaligned = 0;
-	lim->cluster = 1;
+	lim->no_cluster = 0;
 }
 EXPORT_SYMBOL(blk_set_default_limits);
 
@@ -477,6 +477,15 @@
 void blk_queue_stack_limits(struct request_queue *t, struct request_queue *b)
 {
 	blk_stack_limits(&t->limits, &b->limits, 0);
+
+	if (!t->queue_lock)
+		WARN_ON_ONCE(1);
+	else if (!test_bit(QUEUE_FLAG_CLUSTER, &b->queue_flags)) {
+		unsigned long flags;
+		spin_lock_irqsave(t->queue_lock, flags);
+		queue_flag_clear(QUEUE_FLAG_CLUSTER, t);
+		spin_unlock_irqrestore(t->queue_lock, flags);
+	}
 }
 EXPORT_SYMBOL(blk_queue_stack_limits);
 
@@ -552,7 +561,7 @@
 	t->io_min = max(t->io_min, b->io_min);
 	t->io_opt = lcm(t->io_opt, b->io_opt);
 
-	t->cluster &= b->cluster;
+	t->no_cluster |= b->no_cluster;
 
 	/* Physical block size a multiple of the logical block size? */
 	if (t->physical_block_size & (t->logical_block_size - 1)) {
@@ -643,6 +652,17 @@
 		printk(KERN_NOTICE "%s: Warning: Device %s is misaligned\n",
 		       top, bottom);
 	}
+
+	if (!t->queue_lock)
+		WARN_ON_ONCE(1);
+	else if (!test_bit(QUEUE_FLAG_CLUSTER, &b->queue_flags)) {
+		unsigned long flags;
+
+		spin_lock_irqsave(t->queue_lock, flags);
+		if (!test_bit(QUEUE_FLAG_CLUSTER, &b->queue_flags))
+			queue_flag_clear(QUEUE_FLAG_CLUSTER, t);
+		spin_unlock_irqrestore(t->queue_lock, flags);
+	}
 }
 EXPORT_SYMBOL(disk_stack_limits);
 
--- a/drivers/md/dm-table.c
+++ b/drivers/md/dm-table.c
@@ -1082,6 +1082,11 @@
 	 */
 	q->limits = *limits;
 
+	if (limits->no_cluster)
+		queue_flag_clear_unlocked(QUEUE_FLAG_CLUSTER, q);
+	else
+		queue_flag_set_unlocked(QUEUE_FLAG_CLUSTER, q);
+
 	dm_table_set_integrity(t);
 
 	/*
--- a/drivers/md/md.c
+++ b/drivers/md/md.c
@@ -3959,6 +3959,9 @@
 		goto abort;
 	mddev->queue->queuedata = mddev;
 
+	/* Can be unlocked because the queue is new: no concurrency */
+	queue_flag_set_unlocked(QUEUE_FLAG_CLUSTER, mddev->queue);
+
 	blk_queue_make_request(mddev->queue, md_make_request);
 
 	disk = alloc_disk(1 << shift);
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1636,8 +1636,10 @@
 
 	blk_queue_max_segment_size(q, dma_get_max_seg_size(dev));
 
-	if (!shost->use_clustering)
-		q->limits.cluster = 0;
+	if (!shost->use_clustering) {
+		q->limits.no_cluster = 1;
+		queue_flag_clear_unlocked(QUEUE_FLAG_CLUSTER, q);
+	}
 
 	/*
 	 * set a reasonable default alignment on word boundaries: the
--- a/include/linux/blkdev.h
+++ b/include/linux/blkdev.h
@@ -318,7 +318,7 @@
 	unsigned short		max_phys_segments;
 
 	unsigned char		misaligned;
-	unsigned char		cluster;
+	unsigned char		no_cluster;
 };
 
 struct request_queue
@@ -440,6 +440,7 @@
 #endif
 };
 
+#define QUEUE_FLAG_CLUSTER	0	/* cluster several segments into 1 */
 #define QUEUE_FLAG_QUEUED	1	/* uses generic tag queueing */
 #define QUEUE_FLAG_STOPPED	2	/* queue is stopped */
 #define	QUEUE_FLAG_SYNCFULL	3	/* read queue has been filled */
@@ -460,6 +461,7 @@
 #define QUEUE_FLAG_DISCARD     17	/* supports DISCARD */
 
 #define QUEUE_FLAG_DEFAULT	((1 << QUEUE_FLAG_IO_STAT) |		\
+				 (1 << QUEUE_FLAG_CLUSTER) |		\
 				 (1 << QUEUE_FLAG_STACKABLE)	|	\
 				 (1 << QUEUE_FLAG_SAME_COMP))
 
@@ -627,7 +629,7 @@
 
 static inline unsigned int blk_queue_cluster(struct request_queue *q)
 {
-	return q->limits.cluster;
+	return test_bit(QUEUE_FLAG_CLUSTER, &q->queue_flags) && !q->limits.no_cluster;
 }
 
 /*
